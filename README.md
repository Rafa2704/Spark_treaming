# ğŸ“Œ Monitoramento de PreÃ§os de CafÃ© e Ovos com PySpark e AWS Glue

## ğŸ“ DescriÃ§Ã£o Geral
Este projeto tem como objetivo monitorar os preÃ§os de cafÃ© e ovos em tempo real na plataforma Mercado Livre, utilizando AWS Glue Studio para processar dados com PySpark. Os preÃ§os coletados serÃ£o armazenados no AWS S3 e no DynamoDB, permitindo a anÃ¡lise de tendÃªncias e variaÃ§Ãµes ao longo do tempo.
AlÃ©m disso, serÃ¡ feita a verificaÃ§Ã£o dos vendedores, permitindo identificar padrÃµes de preÃ§o por vendedor. A soluÃ§Ã£o permite que usuÃ¡rios acompanhem mudanÃ§as nos preÃ§os, identifiquem oportunidades de compra/venda e recebam insights sobre produtos populares.

## ğŸ¯ Objetivos do Projeto
âœ”ï¸ Coletar e processar dados de preÃ§os de cafÃ© e ovos do Mercado Livre em tempo real, incluindo informaÃ§Ãµes sobre o vendedor.  
âœ”ï¸ Armazenar os preÃ§os histÃ³ricos no AWS S3 para anÃ¡lise futura.  
âœ”ï¸ Salvar os preÃ§os mais recentes no DynamoDB para acesso rÃ¡pido.  
âœ”ï¸ Criar um dashboard interativo para visualizar as tendÃªncias de preÃ§os e variaÃ§Ãµes por vendedor.  
âœ”ï¸ Permitir anÃ¡lise e consultas nos dados usando AWS Athena + Spark SQL.  

## ğŸ“Œ Arquitetura do Projeto

### 1ï¸âƒ£ IngestÃ£o de Dados
Um job PySpark no AWS Glue Studio farÃ¡ chamadas periÃ³dicas Ã  API do Mercado Livre.  
Os dados coletados, incluindo o preÃ§o e o vendedor, serÃ£o armazenados em um bucket no AWS S3.  
As informaÃ§Ãµes mais recentes serÃ£o inseridas no AWS DynamoDB para acesso rÃ¡pido.

### 2ï¸âƒ£ Processamento e AnÃ¡lise
O AWS Glue usarÃ¡ Spark Structured Streaming para processar os dados.  
Os preÃ§os e dados de vendedor serÃ£o analisados para identificar variaÃ§Ãµes, tendÃªncias e padrÃµes.  
AWS Athena permitirÃ¡ consultas SQL nos dados armazenados no S3.

### 3ï¸âƒ£ Armazenamento
- **AWS S3** â†’ Para armazenar os dados histÃ³ricos de preÃ§os e vendedores.  
- **AWS DynamoDB** â†’ Para manter uma base de preÃ§os sempre atualizada com informaÃ§Ãµes sobre vendedores.

### 4ï¸âƒ£ VisualizaÃ§Ã£o e Insights
Criar um dashboard interativo com Streamlit para exibir:
- HistÃ³rico de preÃ§os dos produtos.
- VariaÃ§Ãµes de preÃ§o em tempo real.
- ComparaÃ§Ã£o entre vendedores e produtos semelhantes.
AWS QuickSight ou Grafana podem ser usados para criar relatÃ³rios e grÃ¡ficos mais avanÃ§ados.

## ğŸ“Œ Tecnologias Utilizadas
- **PySpark (Spark Structured Streaming)** â†’ Para coletar e processar os dados.  
- **AWS Glue Studio** â†’ Para gerenciar e executar jobs PySpark.  
- **AWS S3** â†’ Para armazenar os dados coletados em formato JSON/Parquet.  
- **AWS DynamoDB** â†’ Para armazenar os preÃ§os mais recentes, incluindo informaÃ§Ãµes sobre os vendedores.  
- **API do Mercado Livre** â†’ Para obter os dados dos produtos, incluindo vendedores.  
- **AWS Athena + Spark SQL** â†’ Para consultas analÃ­ticas sobre os preÃ§os.  
- **Streamlit / AWS QuickSight** â†’ Para visualizaÃ§Ã£o dos dados.

## ğŸ“Œ Fluxo de Funcionamento
1ï¸âƒ£ AWS Glue Job (PySpark) consulta a API do Mercado Livre periodicamente.  
2ï¸âƒ£ Os dados, incluindo preÃ§os e vendedores, sÃ£o processados e salvos no S3 e no DynamoDB.  
3ï¸âƒ£ Spark Structured Streaming analisa os preÃ§os e os vendedores em tempo real.  
4ï¸âƒ£ AWS Athena permite consultas sobre os preÃ§os histÃ³ricos.  
5ï¸âƒ£ Dashboard (Streamlit/QuickSight) exibe grÃ¡ficos com variaÃ§Ãµes de preÃ§o e vendedores.

## ğŸ“Œ Funcionalidades Principais
âœ”ï¸ Coleta de dados em tempo real da API do Mercado Livre, incluindo informaÃ§Ãµes sobre os vendedores.  
âœ”ï¸ Armazenamento de histÃ³rico de preÃ§os no S3 para anÃ¡lise.  
âœ”ï¸ Monitoramento de variaÃ§Ã£o de preÃ§os e alertas para mudanÃ§as significativas, incluindo anÃ¡lises por vendedor.  
âœ”ï¸ AnÃ¡lise de tendÃªncias para identificar produtos que estÃ£o subindo ou caindo de preÃ§o, alÃ©m de identificar vendedores com os melhores preÃ§os.  
âœ”ï¸ Dashboard interativo para acompanhar os preÃ§os, vendedores e insights de mercado.

## ğŸ“Œ Como Executar o Projeto?

### 1ï¸âƒ£ Criar o Job no AWS Glue Studio
- Acesse o AWS Glue Studio na AWS.
- Clique em "Criar job" â†’ Escolha "CÃ³digo Python".
- Escolha um IAM Role com permissÃµes para acessar S3 e DynamoDB.
- Escolha um S3 bucket para armazenar logs e outputs.
- Copie e cole o cÃ³digo PySpark no editor do Glue.
- Salve e execute o job.

### 2ï¸âƒ£ Monitorar os Dados
- Verifique os arquivos JSON no AWS S3.
- Consulte os dados recentes no DynamoDB, incluindo informaÃ§Ãµes sobre os vendedores.
- Utilize o AWS Athena para rodar queries SQL sobre os preÃ§os e vendedores.

### 3ï¸âƒ£ Criar um Dashboard
- Utilize Streamlit para criar um painel interativo que mostre variaÃ§Ãµes de preÃ§os por vendedor.
- Ou configure o AWS QuickSight para gerar relatÃ³rios visuais mais avanÃ§ados.

## ğŸ“Œ BenefÃ­cios do Projeto
ğŸš€ **AutomatizaÃ§Ã£o total** â†’ Dados coletados e analisados sem intervenÃ§Ã£o manual.  
ğŸ“Š **AnÃ¡lises estratÃ©gicas** â†’ Empresas podem prever tendÃªncias de preÃ§os e identificar os melhores vendedores.  
âš¡ **Escalabilidade** â†’ Pode ser aplicado a qualquer marketplace ou e-commerce.  
ğŸ’¡ **Insights acionÃ¡veis** â†’ Permite identificar oportunidades de compra e venda rapidamente, levando em conta as variaÃ§Ãµes de preÃ§o e o desempenho dos vendedores.

## ğŸ“Œ PrÃ³ximos Passos
ğŸ”¹ Configurar AWS Glue e criar o job PySpark para coletar os dados da API, incluindo informaÃ§Ãµes sobre os vendedores.  
ğŸ”¹ Armazenar os dados no S3 e DynamoDB para processamento contÃ­nuo.  
ğŸ”¹ Criar consultas no AWS Athena para anÃ¡lise dos preÃ§os e vendedores.  
ğŸ”¹ Construir um dashboard interativo para visualizaÃ§Ã£o dos dados, incluindo comparaÃ§Ãµes entre vendedores.

âœ‰ï¸ **Contato**: Caso tenha dÃºvidas ou sugestÃµes, fique Ã  vontade para contribuir! ğŸš€
